########
# -- Configure the Clickhouse deployment.
########
clickhouse:
  enabled: true

  auth:
    username: clickhouse
    password: clickhouse

  zookeeper:
    enabled: true

########
# -- Configure the collector process which is responsible for interfacing with the underlying Clickhouse deployment.
########
collector:
  enabled: true

  mode: deployment
  replicaCount: 1

  config:
    processors:
      batch:
        timeout: 5s
        send_batch_size: 100000

    exporters:
      clickhouse:
        endpoint: "tcp://{{ .Release.Name }}-clickhouse:9000?dial_timeout=10s&compress=lz4"
        database: otel
        username: clickhouse
        password: clickhouse
        ttl: 72h
        logs_table_name: otel_logs
        traces_table_name: otel_traces
        metrics_table_name: otel_metrics
        timeout: 5s
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s

    service:
      pipelines:
        logs:
          exporters:
            - clickhouse
        metrics:
          exporters:
            - clickhouse
        traces:
          exporters:
            - clickhouse

########
# -- Configure the cluster-agent process that monitors and collects metrics for the control plane of your cluster.
########
cluster:
  enabled: true

  nameOverride: "cluster-agent"
  mode: deployment
  replicaCount: 1

  presets:
    kubernetesEvents:
      enabled: true
    clusterMetrics:
      enabled: true

  clusterRole:
    create: true
    rules:
      - verbs: [ "*" ]
        resources: [ "*" ]
        apiGroups: [ "*" ]
      - verbs: [ "*" ]
        nonResourceURLs: [ "*" ]

  config:
    receivers:
      #== cluster
      k8s_cluster:
        collection_interval: 10s
        node_conditions_to_report: [ Ready, MemoryPressure,DiskPressure,NetworkUnavailable ]
        allocatable_types_to_report: [ cpu, memory, storage, ephemeral-storage ]

      #== events
      k8s_events:
        auth_type: "serviceAccount"

      #== control-plane things
      prometheus:
        config:
          scrape_configs:
            #== cadvisor
            - job_name: kubernetes/cadvisor
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              kubernetes_sd_configs:
                - role: node
              relabel_configs:
                - replacement: kubernetes.default.svc.cluster.local:443
                  target_label: __address__
                - regex: (.+)
                  replacement: /api/v1/nodes/$${1}/proxy/metrics/cadvisor
                  source_labels:
                    - __meta_kubernetes_node_name
                  target_label: __metrics_path__
              scheme: https
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: false
                server_name: kubernetes

            #== more kubelet
            - job_name: kubernetes/kubelet
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              kubernetes_sd_configs:
                - role: node
              relabel_configs:
                - replacement: kubernetes.default.svc.cluster.local:443
                  target_label: __address__
                - regex: (.+)
                  replacement: /api/v1/nodes/$${1}/proxy/metrics
                  source_labels:
                    - __meta_kubernetes_node_name
                  target_label: __metrics_path__
              scheme: https
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: false
                server_name: kubernetes

            #== API
            - job_name: kubernetes/apiservers
              kubernetes_sd_configs:
                - role: endpoints
                  namespaces:
                    names:
                      - default
              scheme: https
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              relabel_configs:
                - source_labels: [ __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name ]
                  action: keep
                  regex: kubernetes;https
                - action: replace
                  source_labels:
                    - __meta_kubernetes_namespace
                  target_label: Namespace
                - action: replace
                  source_labels:
                    - __meta_kubernetes_service_name
                  target_label: Service

      # disable these...
      otlp: null
      jaeger: null
      zipkin: null

    processors:
      memory_limiter:
        check_interval: 3s
        limit_mib: 1500
        spike_limit_mib: 500
      resourcedetection/system:
        detectors: [ env, system, gcp, eks ]
        timeout: 2s
        override: false
      batch:
        send_batch_size: 10000
        timeout: 200ms

    exporters:
      otlp/2:
        endpoint: "{{ .Release.Name }}-collector:4317"
        tls:
          insecure: true

    service:
      pipelines:
        traces: null
        metrics:
          exporters:
            - otlp/2
          processors:
            - memory_limiter
            - resourcedetection/system
            - batch
          receivers:
            - k8s_cluster
            - prometheus
        logs:
          exporters:
            - otlp/2
          processors:
            - memory_limiter
            - resourcedetection/system
            - batch
          receivers:
            - k8s_events

########
# -- Configure the node-agent process that monitors and collects metrics for each host in your cluster.
########
node:
  enabled: true

  mode: daemonset
  presets:
    logsCollection:
      enabled: true
    hostMetrics:
      enabled: true
    kubernetesAttributes:
      enabled: true
    kubeletMetrics:
      enabled: true

  extraEnvs:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName

  config:
    receivers:
      #== kubelet
      kubeletstats:
        collection_interval: 10s
        auth_type: "serviceAccount"
        endpoint: https://${env:K8S_NODE_NAME}:10250
        insecure_skip_verify: true
        metric_groups:
          - container
          - pod
          - volume
          - node
        extra_metadata_labels:
          - container.id

      # disable these...
      prometheus: null
      otlp: null
      jaeger: null
      zipkin: null

    processors:
      memory_limiter:
        check_interval: 3s
        limit_mib: 1500
        spike_limit_mib: 500
      resourcedetection/system:
        detectors: [ env, system, gcp, eks ]
        timeout: 2s
        override: false
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: true
        filter:
          node_from_env_var: K8S_NODE_NAME
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.container.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
      batch:
        send_batch_size: 10000
        timeout: 200ms

    exporters:
      otlp/2:
        endpoint: "{{ .Release.Name }}-collector:4317"
        tls:
          insecure: true

    service:
      pipelines:
        traces: null
        metrics:
          exporters:
            - otlp/2
          processors:
            - memory_limiter
            - resourcedetection/system
            - k8sattributes
            - batch
          receivers:
            - hostmetrics
            - kubeletstats
        logs:
          exporters:
            - otlp/2
          processors:
            - memory_limiter
            - resourcedetection/system
            - k8sattributes
            - batch
          receivers:
            - filelog

########
# -- Configure the grafana deployment.
########
grafana:
  enabled: true

  # current configuration does not support multiple...
  replicas: 1

  adminUser: admin
  adminPassword: admin

  plugins:
    - grafana-clickhouse-datasource

  datasources:
    "datasources.yaml":
      apiVersion: 1
      datasources:
        - name: ClickHouse
          type: grafana-clickhouse-datasource
          jsonData:
            defaultDatabase: default
            port: 9000
            host: "{{ .Release.Name }}-clickhouse"
            username: clickhouse
            secure: false
            protocol: native
            logs:
              defaultDatabase: otel
              defaultTable: otel_logs
              otelEnabled: true
              otelVersion: latest
            traces:
              defaultDatabase: otel
              defaultTable: otel_traces
              otelEnabled: true
              otelVersion: latest
              durationUnit: milliseconds
          secureJsonData:
            password: clickhouse
